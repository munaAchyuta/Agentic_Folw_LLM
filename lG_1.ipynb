{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4931ac25-99f9-4f04-b3d1-4683f7853667",
   "metadata": {},
   "source": [
    "# Enviornment "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "568c84d6-9df6-4b7b-b50d-476c0a64a04b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#! pip install -U --quiet langchain_community tiktoken langchain-mistralai langchainhub chromadb langchain langgraph tavily-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3fdde17e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Vectorstore:\n",
    "    data = {\"ArithmeticError\": \"ArithmeticError occurred\", \"AssertionError\": \"Assertion error occurred\", \"LookupError\": \"Lookup\"}\n",
    "    def invoke(self,text):\n",
    "        Vectorstore.data.get(text,\"ArithmeticError\")\n",
    "    \n",
    "    def invoke_new(self,text):\n",
    "        'Yes' if text in Vectorstore.data else 'No'\n",
    "\n",
    "retriever = Vectorstore()\n",
    "retrieval_grader = Vectorstore()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a55238a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "module_meta_schema = {'app.py':\n",
    "                      {'abs_path':'path to file'\n",
    "                      ,'function_name':{'definition':'definition goes here','description':'','params':[{'type':'dict/list/str/int','data':'data sample if any'},]\n",
    "                                        ,'returns':{'type':'dict/list/str/int','data':'data sample if any'}\n",
    "                                        ,'caller_function':'caller function/method name goes here'\n",
    "                                        }\n",
    "                      ,'class_name':{'definition':'class definition goes here'\n",
    "                                     ,'method_name':{'definition':'definition goes here','description':'objective goes here','params':[{'type':'dict/list/str/int','data':'data sample if any'},]\n",
    "                                                     ,'returns':{'type':'dict/list/str/int','data':'data sample if any'}\n",
    "                                                     ,'caller_function':'caller function/method name goes here'\n",
    "                                                     }\n",
    "                                     },\n",
    "                      },\n",
    "                      'car_emi.py':\n",
    "                       {'abs_path':'path to file'\n",
    "                        ,'function_name':{'signature':'definition goes here','description':'','params':[{'type':'dict/list/str/int','data':'data sample if any'},]\n",
    "                                          ,'returns':{'type':'dict/list/str/int','data':'data sample if any'}\n",
    "                                          ,'caller_function':'caller function/method name goes here'\n",
    "                                          }\n",
    "                        ,'class_name':{'signature':'definition goes here'\n",
    "                                       ,'method_name':{'definition':'definition goes here','description':'objective goes here','params':[{'type':'dict/list/str/int','data':'data sample if any'},]\n",
    "                                                       ,'returns':{'type':'dict/list/str/int','data':'data sample if any'}\n",
    "                                                       ,'caller_function':'caller function/method name goes here'\n",
    "                                                       }\n",
    "                                     },\n",
    "                        },\n",
    "                    }\n",
    "def dependency_search_tool(text):\n",
    "    '''text can be module name or function name or module name or class name'''\n",
    "    return module_meta_schema.find(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87194a1b-535a-4593-ab95-5736fae176d1",
   "metadata": {},
   "source": [
    "# Graph \n",
    "\n",
    "We build the above workflow as a graph.\n",
    "\n",
    "## Graph state\n",
    "\n",
    "The graph `state` contains objects that we want to modify in the graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "94b3945f-ef0f-458d-a443-f763903550b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing_extensions import TypedDict\n",
    "from typing import List\n",
    "\n",
    "class GraphState(TypedDict):\n",
    "    \"\"\"\n",
    "    Represents the state of our graph.\n",
    "\n",
    "    Attributes:\n",
    "        question: question\n",
    "        generation: LLM generation\n",
    "        dependency_search: whether to add search\n",
    "        dependency_documents: list of documents \n",
    "    \"\"\"\n",
    "    question : str\n",
    "    generation : str\n",
    "    more_documents : str\n",
    "    documents : str\n",
    "    counter : int = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "efd639c5-82e2-45e6-a94a-6a4039646ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema import Document\n",
    "\n",
    "### Nodes \n",
    "def generate(state):\n",
    "    \"\"\"\n",
    "    Generate test case & code\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        state (dict): New key added to state, generation, that contains LLM generation\n",
    "    \"\"\"\n",
    "    print(\"---GENERATE---\")\n",
    "    question = state[\"question\"]\n",
    "    documents = state[\"documents\"]\n",
    "    \n",
    "    # LLM generation\n",
    "    generation = \"Code generation Node\"\n",
    "    return {\"documents\": documents, \"question\": question, \"generation\": generation}\n",
    "\n",
    "def more_documents_req(state):\n",
    "    \"\"\"\n",
    "    Determines whether the documents are relevant to generate test cases & code\n",
    "    If not enough information present in given documents, we will set a flag to run dependency search\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        state (dict): Filtered out irrelevant documents and updated dep_search state\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"---CHECK DOCUMENT RELEVANCE TO QUESTION---\")\n",
    "    question = state[\"question\"]\n",
    "    documents = state[\"documents\"]\n",
    "    counter = state[\"counter\"]\n",
    "    if counter is None:\n",
    "        counter = 0\n",
    "    \n",
    "    # Score each doc\n",
    "    filtered_docs = []\n",
    "    more_documents = \"No\"\n",
    "    \n",
    "    score = retrieval_grader.invoke_new('ArithmeticError')\n",
    "    grade = 'NO'#score.binary_score\n",
    "    \n",
    "    if grade.lower() == \"yes\":\n",
    "        print(\"---GRADE: DOCUMENT RELEVANT---\")\n",
    "        documents + \"new dependency function goes here\"\n",
    "    else:\n",
    "        print(\"---GRADE: DOCUMENT NOT RELEVANT---\")\n",
    "        more_documents = \"Yes\"\n",
    "    \n",
    "    return {\"documents\": documents, \"question\": question, \"more_documents\": more_documents, \"counter\": counter+1}\n",
    "\n",
    "### Edges\n",
    "\n",
    "def decide_to_generate(state):\n",
    "    \"\"\"\n",
    "    Determines whether to generate an answer, or add dependency search\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        str: Binary decision for next node to call\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"---ASSESS GRADED DOCUMENTS---\")\n",
    "    question = state[\"question\"]\n",
    "    more_documents = state[\"more_documents\"]\n",
    "    documents = state[\"documents\"]\n",
    "    counter = state['counter']\n",
    "\n",
    "    if counter >= 5:\n",
    "        print(\"---DECISION: GENERATE ENDED with counter exceed---\")\n",
    "        return \"generate\"\n",
    "    if more_documents == \"Yes\":\n",
    "        # All documents have been filtered check_relevance\n",
    "        # We will re-generate a new query\n",
    "        print(\"---DECISION: ALL DOCUMENTS ARE NOT RELEVANT TO QUESTION, INCLUDE WEB SEARCH---\")\n",
    "        return \"more_documents_req\"\n",
    "    else:\n",
    "        # We have relevant documents, so generate answer\n",
    "        print(\"---DECISION: GENERATE---\")\n",
    "        return \"generate\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa076e90-7132-4fcf-8507-db5990314c4f",
   "metadata": {},
   "source": [
    "## Build Graph\n",
    "\n",
    "This follows the flow we outlined in the figure above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dedae17a-98c6-474d-90a7-9234b7c8cea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import END, StateGraph\n",
    "\n",
    "workflow = StateGraph(GraphState)\n",
    "\n",
    "# Define the nodes\n",
    "workflow.add_node(\"generate\", generate)  # generatae\n",
    "workflow.add_node(\"more_documents_req\", more_documents_req)  # web search\n",
    "\n",
    "# Build graph\n",
    "workflow.set_entry_point(\"more_documents_req\")\n",
    "workflow.add_edge(\"more_documents_req\", \"generate\")\n",
    "workflow.add_conditional_edges(\n",
    "    \"more_documents_req\",\n",
    "    decide_to_generate,\n",
    "    {\n",
    "        \"more_documents_req\": \"more_documents_req\",\n",
    "        \"generate\": \"generate\",\n",
    "    },\n",
    ")\n",
    "workflow.add_edge(\"generate\", END)\n",
    "\n",
    "# Compile\n",
    "app = workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f51afa00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': <langgraph.channels.last_value.LastValue at 0x296451c4e00>,\n",
       " 'generation': <langgraph.channels.last_value.LastValue at 0x296451c5160>,\n",
       " 'more_documents': <langgraph.channels.last_value.LastValue at 0x296453a9a30>,\n",
       " 'documents': <langgraph.channels.last_value.LastValue at 0x296443a4920>,\n",
       " 'counter': <langgraph.channels.last_value.LastValue at 0x296443a68d0>,\n",
       " '__start__': <langgraph.channels.ephemeral_value.EphemeralValue at 0x296451c4da0>,\n",
       " 'generate': <langgraph.channels.ephemeral_value.EphemeralValue at 0x296453aeff0>,\n",
       " 'more_documents_req': <langgraph.channels.ephemeral_value.EphemeralValue at 0x296453aca10>,\n",
       " 'start:more_documents_req': <langgraph.channels.ephemeral_value.EphemeralValue at 0x296453ae060>,\n",
       " 'branch:more_documents_req:decide_to_generate:more_documents_req': <langgraph.channels.ephemeral_value.EphemeralValue at 0x296453aea80>,\n",
       " 'branch:more_documents_req:decide_to_generate:generate': <langgraph.channels.ephemeral_value.EphemeralValue at 0x296453aeea0>}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#dir(app)\n",
    "app.channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f5b7c2fe-1fc7-4b76-bf93-ba701a40aa6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---CHECK DOCUMENT RELEVANCE TO QUESTION---\n",
      "---GRADE: DOCUMENT NOT RELEVANT---\n",
      "---ASSESS GRADED DOCUMENTS---\n",
      "---DECISION: ALL DOCUMENTS ARE NOT RELEVANT TO QUESTION, INCLUDE WEB SEARCH---\n",
      "'Finished running: more_documents_req:'\n",
      "---GENERATE---\n",
      "---CHECK DOCUMENT RELEVANCE TO QUESTION---\n",
      "---GRADE: DOCUMENT NOT RELEVANT---\n",
      "---ASSESS GRADED DOCUMENTS---\n",
      "---DECISION: ALL DOCUMENTS ARE NOT RELEVANT TO QUESTION, INCLUDE WEB SEARCH---\n",
      "'Finished running: generate:'\n",
      "'Finished running: more_documents_req:'\n"
     ]
    },
    {
     "ename": "InvalidUpdateError",
     "evalue": "Invalid update for channel question with values ['ArithmeticError', 'ArithmeticError']",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidUpdateError\u001b[0m                        Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\Achyuta\\anaconda3\\envs\\myenv\\Lib\\site-packages\\langgraph\\pregel\\__init__.py:1872\u001b[0m, in \u001b[0;36m_apply_writes\u001b[1;34m(checkpoint, channels, pending_writes, get_next_version)\u001b[0m\n\u001b[0;32m   1871\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1872\u001b[0m     updated \u001b[38;5;241m=\u001b[39m \u001b[43mchannels\u001b[49m\u001b[43m[\u001b[49m\u001b[43mchan\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvals\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1873\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidUpdateError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32mc:\\Users\\Achyuta\\anaconda3\\envs\\myenv\\Lib\\site-packages\\langgraph\\channels\\last_value.py:55\u001b[0m, in \u001b[0;36mLastValue.update\u001b[1;34m(self, values)\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(values) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m---> 55\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m InvalidUpdateError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLastValue can only receive one value per step.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     57\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalue \u001b[38;5;241m=\u001b[39m values[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n",
      "\u001b[1;31mInvalidUpdateError\u001b[0m: LastValue can only receive one value per step.",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mInvalidUpdateError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpprint\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m pprint\n\u001b[0;32m      2\u001b[0m inputs \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquestion\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mArithmeticError\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdocuments\u001b[39m\u001b[38;5;124m\"\u001b[39m:\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mArithmeticError\u001b[39m\u001b[38;5;124m\"\u001b[39m}\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43moutput\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mapp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43moutput\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpprint\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mFinished running: \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mkey\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m:\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Achyuta\\anaconda3\\envs\\myenv\\Lib\\site-packages\\langgraph\\pregel\\__init__.py:1126\u001b[0m, in \u001b[0;36mPregel.stream\u001b[1;34m(self, input, config, stream_mode, output_keys, input_keys, interrupt_before, interrupt_after, debug)\u001b[0m\n\u001b[0;32m   1121\u001b[0m     print_step_writes(\n\u001b[0;32m   1122\u001b[0m         step, pending_writes, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstream_channels_list\n\u001b[0;32m   1123\u001b[0m     )\n\u001b[0;32m   1125\u001b[0m \u001b[38;5;66;03m# apply writes to channels\u001b[39;00m\n\u001b[1;32m-> 1126\u001b[0m \u001b[43m_apply_writes\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1127\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcheckpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1128\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchannels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1129\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpending_writes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1130\u001b[0m \u001b[43m    \u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1131\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheckpointer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_next_version\u001b[49m\n\u001b[0;32m   1132\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheckpointer\u001b[49m\n\u001b[0;32m   1133\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_increment\u001b[49m\n\u001b[0;32m   1134\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1135\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1137\u001b[0m \u001b[38;5;66;03m# yield values output\u001b[39;00m\n\u001b[0;32m   1138\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalues\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m stream_modes:\n",
      "File \u001b[1;32mc:\\Users\\Achyuta\\anaconda3\\envs\\myenv\\Lib\\site-packages\\langgraph\\pregel\\__init__.py:1874\u001b[0m, in \u001b[0;36m_apply_writes\u001b[1;34m(checkpoint, channels, pending_writes, get_next_version)\u001b[0m\n\u001b[0;32m   1872\u001b[0m     updated \u001b[38;5;241m=\u001b[39m channels[chan]\u001b[38;5;241m.\u001b[39mupdate(vals)\n\u001b[0;32m   1873\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidUpdateError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m-> 1874\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m InvalidUpdateError(\n\u001b[0;32m   1875\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid update for channel \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mchan\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m with values \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvals\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1876\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[0;32m   1877\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m updated \u001b[38;5;129;01mand\u001b[39;00m get_next_version \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1878\u001b[0m     checkpoint[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchannel_versions\u001b[39m\u001b[38;5;124m\"\u001b[39m][chan] \u001b[38;5;241m=\u001b[39m get_next_version(\n\u001b[0;32m   1879\u001b[0m         max_version, channels[chan]\n\u001b[0;32m   1880\u001b[0m     )\n",
      "\u001b[1;31mInvalidUpdateError\u001b[0m: Invalid update for channel question with values ['ArithmeticError', 'ArithmeticError']"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "inputs = {\"question\": \"ArithmeticError\",\"documents\":\"ArithmeticError\"}\n",
    "for output in app.stream(inputs):\n",
    "    for key, value in output.items():\n",
    "        pprint(f\"Finished running: {key}:\")\n",
    "pprint(value[\"generation\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6f680d9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
